{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "def generate(X, alpha, beta, eta, gamma, estimator=\"LATE\"):\n",
    "    phi = torch.sigmoid(X@beta)\n",
    "    c1, c2, c3, c4 = phi[:,0], phi[:,1], phi[:,2], phi[:,3]\n",
    "    if estimator == 'LATE':\n",
    "        c0 = torch.tanh(X @ alpha)\n",
    "    elif estimator == 'MLATE':\n",
    "        c0 = torch.exp(X @ alpha)\n",
    "    c5 = torch.exp(X@eta)\n",
    "    if estimator == 'LATE':\n",
    "        f0 = (c5*(2-c0)+c0-torch.sqrt(c0**2 * (c5-1)**2 + 4*c5)) / (2 * (c5-1))\n",
    "        f1 = f0 + c0\n",
    "    elif estimator == 'MLATE':\n",
    "        f0 = (-(c0+1)*c5+torch.sqrt(c5**2*(c0-1)**2 + 4*c0*c5)) / (2*c0*(1-c5))\n",
    "        f1 = f0 * c0\n",
    "    p011 = (1-c1)*(1-c2)*c3\n",
    "    p001 = (1-c1)*(1-c2)*(1-c3)\n",
    "    p110 = (1-c1)*c2*c4\n",
    "    p100 = (1-c1)*c2*(1-c4)\n",
    "    p111 = f1*c1 + p110\n",
    "    p010 = f0*c1 + p011\n",
    "    p101 = 1-p001-p011-p111\n",
    "    p000 = 1-p010-p100-p110\n",
    "    VIden = torch.sigmoid(X @ gamma)\n",
    "\n",
    "    Z = torch.bernoulli(VIden)\n",
    "\n",
    "    p1 = torch.column_stack((p001, p101, p011, p111))\n",
    "    p0 = torch.column_stack((p000, p100, p010, p110))\n",
    "    p = Z.unsqueeze(1) * p1 + (1-Z).unsqueeze(1) * p0\n",
    "    idx = torch.multinomial(p, num_samples=1).squeeze(1)\n",
    "    cand = torch.LongTensor([[0,0], [1,0], [0,1], [1,1]])\n",
    "    DY = cand[idx]\n",
    "    return Z, DY[:,0], DY[:,1]\n",
    "\n",
    "def nll(X,Z,D,Y,alpha,beta,eta,gamma,estimator='LATE'):\n",
    "    phi = torch.sigmoid(X@beta)\n",
    "    c1, c2, c3, c4 = phi[:,0], phi[:,1], phi[:,2], phi[:,3]\n",
    "    if estimator == 'LATE':\n",
    "        c0 = torch.tanh(X @ alpha)\n",
    "    elif estimator == 'MLATE':\n",
    "        c0 = torch.exp(X @ alpha)\n",
    "    c5 = torch.exp(X@eta)\n",
    "    if estimator == 'LATE':\n",
    "        f0 = (c5*(2-c0)+c0-torch.sqrt(c0**2 * (c5-1)**2 + 4*c5)) / (2 * (c5-1))\n",
    "        f1 = f0 + c0\n",
    "    elif estimator == 'MLATE':\n",
    "        f0 = (-(c0+1)*c5+torch.sqrt(c5**2*(c0-1)**2 + 4*c0*c5)) / (2*c0*(1-c5))\n",
    "        f1 = f0 * c0\n",
    "    p011 = (1-c1)*(1-c2)*c3\n",
    "    p001 = (1-c1)*(1-c2)*(1-c3)\n",
    "    p110 = (1-c1)*c2*c4\n",
    "    p100 = (1-c1)*c2*(1-c4)\n",
    "    p111 = f1*c1 + p110\n",
    "    p010 = f0*c1 + p011\n",
    "    p101 = 1-p001-p011-p111\n",
    "    p000 = 1-p010-p100-p110\n",
    "\n",
    "    d = torch.sigmoid(X@gamma)\n",
    "    l = D*Y*Z*p111*d + (1-D)*Y*Z*p011*d + D*(1-Y)*Z*p101*d + (1-D)*(1-Y)*Z*p001*d + D*Y*(1-Z)*p110*(1-d) + (1-D)*Y*(1-Z)*p010*(1-d) + D*(1-Y)*(1-Z)*p100*(1-d) + (1-D)*(1-Y)*(1-Z)*p000*(1-d)\n",
    "    return torch.mean(torch.log(l.clamp(1e-10)))\n",
    "\n",
    "def square_loss(X, Z, D, Y, alpha, beta, gamma, eta, estimator, strategy='identity'):\n",
    "    d = torch.sigmoid(X@gamma)\n",
    "    phi = torch.sigmoid(X@beta)\n",
    "    phi1, phi2, phi3, phi4 = phi[:,0], phi[:,1], phi[:,2], phi[:,3]\n",
    "    OP = torch.exp(X@eta)\n",
    "    f = (d**Z) * ((1-d)**(1-Z))\n",
    "    if estimator == 'LATE':\n",
    "        theta = torch.tanh(X@alpha)\n",
    "        H = Y - D * theta\n",
    "        f0 = (OP*(2-theta)+theta-torch.sqrt(theta**2*(OP-1)**2+4*OP))/(2*(OP-1))\n",
    "        f1 = f0 + theta\n",
    "        E = f0*phi1 + (1-phi1)*(1-phi2)*phi3 + (1-phi1)*phi2*phi4 - theta*(1-phi1)*phi2\n",
    "    elif estimator == 'MLATE':\n",
    "        theta = torch.exp(X@alpha)\n",
    "        H = Y * theta**(-D)\n",
    "        f0 = (-(theta+1)*OP+torch.sqrt(OP**2*(theta-1)**2+4*theta*OP)) / (2*theta*(1-OP))\n",
    "        f1 = f0 * theta\n",
    "        E = f0*phi1 + (1-phi1)*phi2*phi4/theta + (1-phi1)*(1-phi2)*phi3\n",
    "    \n",
    "    if strategy == 'identity':\n",
    "        return torch.sum((torch.sum(X*((2*Z-1)*(H-E)/f).unsqueeze(1), dim=0))**2)\n",
    "    elif strategy == 'optimal':\n",
    "        p011 = (1-phi1)*(1-phi2)*phi3\n",
    "        p001 = (1-phi1)*(1-phi2)*(1-phi3)\n",
    "        p110 = (1-phi1)*phi2*phi4\n",
    "        p100 = (1-phi1)*phi2*(1-phi4)\n",
    "        p111 = f1*phi1 + p110\n",
    "        p010 = f0*phi1 + p011\n",
    "        p101 = 1-p001-p011-p111\n",
    "        p000 = 1-p010-p100-p110\n",
    "        if estimator == 'LATE':\n",
    "            EH2_1 = p011+p111+ theta**2 * (p111+p101) -2*theta*p111\n",
    "            EH2_0 = p110+p010+theta**2*(p110+p100) -2*theta*p110\n",
    "            EH_1 = p111+p011-theta*(p111+p101)\n",
    "            EH_0 = p110+p010-theta*(p110+p100)\n",
    "            EZX = (EH2_1-EH_1**2) / d + (EH2_0-EH_0**2)/(1-d)\n",
    "            w = -X * ((1/torch.cosh(X@alpha)**2) * phi1 / EZX).unsqueeze(1)\n",
    "            return torch.sum((torch.sum(w*((2*Z-1)*(H-E)/f).unsqueeze(1), dim=0))**2)\n",
    "        elif estimator == 'MLATE':\n",
    "            EH2_1 = p111/theta**2+p101\n",
    "            EH2_0 = p110/theta**2+p100\n",
    "            EH_1 = p111/theta+p101\n",
    "            EH_0 = p110/theta+p100\n",
    "            EZX = (EH2_1-EH_1**2) / d + (EH2_0-EH_0**2)/(1-d)\n",
    "            w = -X * (1 / theta * f1 * phi1 / EZX).unsqueeze(1)\n",
    "            return torch.sum((torch.sum(w*((2*Z-1)*(H-E)/f).unsqueeze(1), dim=0))**2)\n",
    "\n",
    "def MLE(X, estimator='LATE', dr=True):\n",
    "    alpha0 = torch.tensor([0.0, -1.0])\n",
    "    beta0 = (torch.ones(size=(4,2)) * torch.tensor([-0.4,0.8])).T\n",
    "    eta0 = torch.tensor([-0.4, 1.0])\n",
    "    gamma0 = torch.tensor([0.1, -1.0])\n",
    "    Z, D, Y = generate(X, alpha0, beta0, eta0, gamma0, estimator)\n",
    "    minimum = (-nll(X,Z,D,Y,alpha0,beta0,eta0,gamma0, estimator)).item()\n",
    "    # alpha = nn.Parameter(torch.tensor([0.5, 0.5]))\n",
    "    # beta = nn.Parameter((torch.ones(size=(4,2)) * torch.tensor([-0.5,0.5])).T)\n",
    "    # eta = nn.Parameter(torch.tensor([-0.5, 0.5]))\n",
    "    # gamma = nn.Parameter(torch.tensor([0.2, 0.5]))\n",
    "    alpha = nn.Parameter(torch.rand(size=(2,))*2-1)\n",
    "    beta = nn.Parameter(torch.rand(size=(2,4))*2-1)\n",
    "    eta = nn.Parameter(torch.rand(size=(2,))*2-1)\n",
    "    gamma = nn.Parameter(torch.rand(size=(2,))*2-1)\n",
    "    opt = torch.optim.Adam(params=(alpha, beta, eta, gamma), lr=1e-3, weight_decay=0)\n",
    "    optloss = float('inf')\n",
    "    for i in range(10000):\n",
    "        opt.zero_grad()\n",
    "        loss = -nll(X,Z,D,Y,alpha,beta,eta,gamma, estimator)\n",
    "        if loss.item() < optloss:\n",
    "            if abs(loss.item() - optloss) < 1e-6:\n",
    "                break\n",
    "            optloss = loss.item()\n",
    "            mlealpha = alpha.detach().clone()\n",
    "            mlebeta = beta.detach().clone()\n",
    "            mleeta = eta.detach().clone()\n",
    "            mlegamma = gamma.detach().clone()\n",
    "        # print('Iter {} | loss {:.04f}'.format(i+1, loss.item()))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    if not dr:\n",
    "        return mlealpha, mlebeta, mleeta, mlegamma, minimum, optloss\n",
    "\n",
    "    alpha = nn.Parameter(mlealpha.clone(),requires_grad=True)\n",
    "    # alpha = nn.Parameter(torch.rand(size=(2,))*2-1)\n",
    "    opt = torch.optim.Adam(params=(alpha,), lr=1e-3, weight_decay=0)\n",
    "    sqoptloss = float('inf')\n",
    "    for i in range(10000):\n",
    "        opt.zero_grad()\n",
    "        sq_loss = square_loss(X, Z, D, Y, alpha, mlebeta, mlegamma, mleeta, estimator)\n",
    "        # print('Iter {} | sq_loss {:.04f}'.format(i+1, sq_loss.item()), alpha)\n",
    "        if sq_loss.item() < sqoptloss:\n",
    "            sqoptloss = sq_loss.item()\n",
    "            drualpha = alpha.detach().clone()\n",
    "            if abs(sqoptloss) < 1e-6:\n",
    "                break\n",
    "        sq_loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    alpha = nn.Parameter(mlealpha.clone(),requires_grad=True)\n",
    "    opt = torch.optim.Adam(params=(alpha,), lr=1e-3, weight_decay=0)\n",
    "    sqoptloss = float('inf')\n",
    "    for i in range(10000):\n",
    "        opt.zero_grad()\n",
    "        sq_loss = square_loss(X, Z, D, Y, alpha, mlebeta, mlegamma, mleeta, estimator, strategy='optimal')\n",
    "        if sq_loss.item() < sqoptloss:\n",
    "            sqoptloss = sq_loss.item()\n",
    "            drwalpha = alpha.detach().clone()\n",
    "            if abs(sqoptloss) < 1e-6:\n",
    "                break\n",
    "        sq_loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return mlealpha, drualpha, drwalpha, mlebeta, mleeta, mlegamma, minimum, optloss\n",
    "\n",
    "\n",
    "def mle_dr_bth(estimator='LATE'):\n",
    "    N = 1000\n",
    "    NR = 1000\n",
    "    torch.manual_seed(24)\n",
    "    mlealphas = torch.zeros(size=(NR, 2))\n",
    "    drualphas = torch.zeros(size=(NR, 2))\n",
    "    drwalphas = torch.zeros(size=(NR, 2))\n",
    "    minimums, optlosses = [], []\n",
    "    X = torch.column_stack((torch.ones(N)*1.0, torch.rand(N)*2-1))\n",
    "    Xpl = torch.column_stack((torch.ones(N)*1.0, torch.rand(N)*2-1))\n",
    "    Xpr = torch.column_stack((torch.cat((torch.ones(N/2), torch.zeros(N/2))), torch.cat((torch.zeros(N/2), torch.ones(N/2)))))\n",
    "\n",
    "    for i in range(NR):\n",
    "        mlealpha, drualpha,drwalpha, mlebeta, mleeta, mlegamma, minimum, optloss = MLE(X, Xpl, Xpr,  estimator=estimator, dr=True)\n",
    "        print('{} Experiement | Difference {:.04f} | MLEAlpha: ({:.04f}, {:.04f}) | drualpha: ({:.04f}, {:.04f}) | drwalpha: ({:.04f}, {:.04f})'.format(i+1, optloss-minimum, mlealpha[0].item(), mlealpha[1].item(), drualpha[0].item(), drualpha[1].item(),drwalpha[0].item(), drwalpha[1].item()))\n",
    "        mlealphas[i] = mlealpha\n",
    "        drualphas[i] = drualpha\n",
    "        drwalphas[i] = drwalpha\n",
    "        minimums.append(minimum)\n",
    "        optlosses.append(optloss)\n",
    "    torch.save(mlealphas, 'mle_bth_'+estimator+'.pt')\n",
    "    torch.save(drualphas, 'dru_bth_'+estimator+'.pt')\n",
    "    torch.save(drwalphas, 'drw_bth_'+estimator+'.pt')\n",
    "###\n",
    "##对初值敏感(没有先验知识时可能造成无法训练出来)，对学习率敏感\n",
    "##添加贝叶斯先验分布时可能的改进\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
