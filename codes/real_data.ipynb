{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(X,Z,D,Y,alpha,beta,eta,gamma,estimator='LATE'):\n",
    "    # print(X.type(), beta.type())\n",
    "    phi = torch.sigmoid(X@beta)\n",
    "    c1, c3 = phi[:,0], phi[:,1]\n",
    "    if estimator == 'LATE':\n",
    "        c0 = torch.tanh(X @ alpha)\n",
    "    elif estimator == 'MLATE':\n",
    "        c0 = torch.exp(X @ alpha)\n",
    "    c5 = torch.exp(X@eta)\n",
    "    # c5 = c5 * (torch.abs(c5-1) > 1e-10) + (torch.abs(c5-1) <= 1e-10) * (c5-1 >= 0.0) * (1+1e-10) + (torch.abs(c5-1) <= 1e-10) * (c5-1< 0.0) * (1-1e-10)\n",
    "    # c5 = 1 + c5 - c5.clamp(1-1e-5,1+1e-5)\n",
    "    c0 = c0.clamp(1e-10)\n",
    "    if estimator == 'LATE':\n",
    "        f0 = (c5*(2-c0)+c0-torch.sqrt(c0**2 * (c5-1)**2 + 4*c5)) / (2 * (c5-1))\n",
    "        f1 = f0 + c0\n",
    "    elif estimator == 'MLATE':\n",
    "        f0 = torch.where(torch.abs(c5-1)>1e-10, (-(c0+1)*c5+torch.sqrt(c5**2*(c0-1)**2 + 4*c0*c5)) / (2*c0*(1-c5)), -(-c0-1+(2*(c0-1)**2+4*c0)/(c0+1)/2)/(2*c0))\n",
    "        f1 = f0 * c0\n",
    "    p011 = (1-c1)*c3\n",
    "    p001 = (1-c1)*(1-c3)\n",
    "    p110 = 0\n",
    "    p100 = 0\n",
    "    p111 = f1*c1 + p110\n",
    "    p010 = f0*c1 + p011\n",
    "    p101 = 1-p001-p011-p111\n",
    "    p000 = 1-p010-p100-p110\n",
    "\n",
    "    d = torch.sigmoid(X@gamma)\n",
    "    l = D*Y*Z*p111*d + (1-D)*Y*Z*p011*d + D*(1-Y)*Z*p101*d + (1-D)*(1-Y)*Z*p001*d + (1-D)*Y*(1-Z)*p010*(1-d) + (1-D)*(1-Y)*(1-Z)*p000*(1-d)\n",
    "    # if torch.mean(torch.log(l.clamp(1e-10, 1))) :\n",
    "    #     print(l)\n",
    "    #     sys.exit(0)\n",
    "    return torch.mean(torch.log(l.clamp(1e-10)))\n",
    "\n",
    "def square_loss(X, Z, D, Y, alpha, beta, gamma, eta, estimator, strategy='identity'):\n",
    "    d = torch.sigmoid(X@gamma)\n",
    "    phi = torch.sigmoid(X@beta)\n",
    "    phi1, phi3 = phi[:,0], phi[:,1]\n",
    "    OP = torch.exp(X@eta)\n",
    "    f = (d**Z) * ((1-d)**(1-Z))\n",
    "    if estimator == 'LATE':\n",
    "        theta = torch.tanh(X@alpha)\n",
    "        H = Y - D * theta\n",
    "        f0 = (OP*(2-theta)+theta-torch.sqrt(theta**2*(OP-1)**2+4*OP))/(2*(OP-1))\n",
    "        f1 = f0 + theta\n",
    "        E = f0*phi1 + (1-phi1)*phi3\n",
    "    elif estimator == 'MLATE':\n",
    "        theta = torch.exp(X@alpha)\n",
    "        H = Y * theta**(-D)\n",
    "        f0 = (-(theta+1)*OP+torch.sqrt(OP**2*(theta-1)**2+4*theta*OP)) / (2*theta*(1-OP))\n",
    "        f1 = f0 * theta\n",
    "        E = f0*phi1 +(1-phi1)*phi3\n",
    "    \n",
    "    if strategy == 'identity':\n",
    "        return torch.sum((torch.sum(X*((2*Z-1)*(H-E)/f).unsqueeze(1), dim=0))**2)\n",
    "    elif strategy == 'optimal':\n",
    "        p011 = (1-phi1)*phi3\n",
    "        p001 = (1-phi1)*(1-phi3)\n",
    "        p110 = 0\n",
    "        p100 = 0\n",
    "        p111 = f1*phi1 + p110\n",
    "        p010 = f0*phi1 + p011\n",
    "        p101 = 1-p001-p011-p111\n",
    "        p000 = 1-p010-p100-p110\n",
    "        if estimator == 'LATE':\n",
    "            EH2_1 = p011+p111+ theta**2 * (p111+p101) -2*theta*p111\n",
    "            EH2_0 = p110+p010+theta**2*(p110+p100) -2*theta*p110\n",
    "            EH_1 = p111+p011-theta*(p111+p101)\n",
    "            EH_0 = p110+p010-theta*(p110+p100)\n",
    "            EZX = (EH2_1-EH_1**2) / d + (EH2_0-EH_0**2)/(1-d)\n",
    "            w = -X * ((1/torch.cosh(X@alpha)**2) * phi1 / EZX).unsqueeze(1)\n",
    "            return torch.sum((torch.sum(w*((2*Z-1)*(H-E)/f).unsqueeze(1), dim=0))**2)\n",
    "        elif estimator == 'MLATE':\n",
    "            EH2_1 = p111/theta**2+p101\n",
    "            EH2_0 = p110/theta**2+p100\n",
    "            EH_1 = p111/theta+p101\n",
    "            EH_0 = p110/theta+p100\n",
    "            EZX = (EH2_1-EH_1**2) / d + (EH2_0-EH_0**2)/(1-d)\n",
    "            w = -X * (1 / theta * f1 * phi1 / EZX).unsqueeze(1)\n",
    "            return torch.mean((torch.sum(w*((2*Z-1)*(H-E)/f).unsqueeze(1), dim=0))**2)\n",
    "\n",
    "def MLE(X, Z, D ,Y, estimator='MLATE', dr=False):\n",
    "    N, p = X.shape\n",
    "    alpha = nn.Parameter(torch.rand(size=(p,))*0.2-0.1)\n",
    "    beta = nn.Parameter(torch.rand(size=(p,2))*0.2-0.1) ## only phi1 and phi3\n",
    "    eta = nn.Parameter(torch.rand(size=(p,))*2-1)\n",
    "    gamma = nn.Parameter(torch.rand(size=(p,))*0.2-0.1)\n",
    "    opt = torch.optim.Adam(params=(alpha, beta, eta, gamma), lr=1e-3, weight_decay=0)\n",
    "    optloss = float('inf')\n",
    "    for i in range(20000):\n",
    "        opt.zero_grad()\n",
    "        loss = -nll(X,Z,D,Y,alpha,beta,eta,gamma, estimator)\n",
    "        if loss.item() < optloss:\n",
    "            if abs(loss.item() - optloss) < 1e-7:\n",
    "                break\n",
    "            optloss = loss.item()\n",
    "            mlealpha = alpha.detach().clone()\n",
    "            mlebeta = beta.detach().clone()\n",
    "            mleeta = eta.detach().clone()\n",
    "            mlegamma = gamma.detach().clone()\n",
    "        if i % 100 ==0: \n",
    "            # print(alpha, beta, gamma, eta)\n",
    "            print('Iter {} | loss {:.04f}'.format(i+1, loss.item()))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    if not dr:\n",
    "        return mlealpha, mlebeta, mleeta, mlegamma\n",
    "    alpha = nn.Parameter(mlealpha.clone(),requires_grad=True)\n",
    "    # alpha = nn.Parameter(torch.rand(size=(2,))*2-1)\n",
    "    opt = torch.optim.Adam(params=(alpha,), lr=5e-3, weight_decay=0)\n",
    "    sqoptloss = float('inf')\n",
    "    for i in range(100000):\n",
    "        opt.zero_grad()\n",
    "        sq_loss = square_loss(X, Z, D, Y, alpha, mlebeta, mlegamma, mleeta, estimator, strategy='optimal')\n",
    "        if i % 100 ==0:\n",
    "            print('Iter {} | sq_loss {:.04f}'.format(i+1, sq_loss.item()))\n",
    "        if sq_loss.item() < sqoptloss:\n",
    "            sqoptloss = sq_loss.item()\n",
    "            drwalpha = alpha.detach().clone()\n",
    "            if abs(sqoptloss) < 1e-6:\n",
    "                break\n",
    "        sq_loss.backward()\n",
    "        opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1 | loss 1.5820\n",
      "Iter 101 | loss 1.4942\n",
      "Iter 201 | loss 1.4743\n",
      "Iter 301 | loss 1.4635\n",
      "Iter 401 | loss 1.4546\n",
      "Iter 501 | loss 1.4482\n",
      "Iter 601 | loss 1.4440\n",
      "Iter 701 | loss 1.4400\n",
      "Iter 801 | loss 1.4364\n",
      "Iter 901 | loss 1.4335\n",
      "Iter 1001 | loss 1.4309\n",
      "Iter 1101 | loss 1.4287\n",
      "Iter 1201 | loss 1.4259\n",
      "Iter 1301 | loss 1.4242\n",
      "Iter 1401 | loss 1.4228\n",
      "Iter 1501 | loss 1.4216\n",
      "Iter 1601 | loss 1.4205\n",
      "Iter 1701 | loss 1.4197\n",
      "Iter 1801 | loss 1.4188\n",
      "Iter 1901 | loss 1.4179\n",
      "Iter 2001 | loss 1.4170\n",
      "Iter 2101 | loss 1.4162\n",
      "Iter 2201 | loss 1.4153\n",
      "Iter 2301 | loss 1.4145\n",
      "Iter 2401 | loss 1.4136\n",
      "Iter 2501 | loss 1.4127\n",
      "Iter 2601 | loss 1.4118\n",
      "Iter 2701 | loss 1.4109\n",
      "Iter 2801 | loss 1.4100\n",
      "Iter 2901 | loss 1.4091\n",
      "Iter 3001 | loss 1.4083\n",
      "Iter 3101 | loss 1.4074\n",
      "Iter 3201 | loss 1.4066\n",
      "Iter 3301 | loss 1.4058\n",
      "Iter 3401 | loss 1.4050\n",
      "Iter 3501 | loss 1.4042\n",
      "Iter 3601 | loss 1.4033\n",
      "Iter 3701 | loss 1.4025\n",
      "Iter 3801 | loss 1.4017\n",
      "Iter 3901 | loss 1.4010\n",
      "Iter 4001 | loss 1.4002\n",
      "Iter 4101 | loss 1.3994\n",
      "Iter 4201 | loss 1.3986\n",
      "Iter 4301 | loss 1.3979\n",
      "Iter 4401 | loss 1.3972\n",
      "Iter 4501 | loss 1.3964\n",
      "Iter 4601 | loss 1.3957\n",
      "Iter 4701 | loss 1.3950\n",
      "Iter 4801 | loss 1.3944\n",
      "Iter 4901 | loss 1.3937\n",
      "Iter 5001 | loss 1.3930\n",
      "Iter 5101 | loss 1.3924\n",
      "Iter 5201 | loss 1.3918\n",
      "Iter 5301 | loss 1.3912\n",
      "Iter 5401 | loss 1.3906\n",
      "Iter 5501 | loss 1.3901\n",
      "Iter 5601 | loss 1.3895\n",
      "Iter 5701 | loss 1.3890\n",
      "Iter 5801 | loss 1.3885\n",
      "Iter 5901 | loss 1.3880\n",
      "Iter 6001 | loss 1.3875\n",
      "Iter 6101 | loss 1.3870\n",
      "Iter 6201 | loss 1.3865\n",
      "Iter 6301 | loss 1.3861\n",
      "Iter 6401 | loss 1.3857\n",
      "Iter 6501 | loss 1.3853\n",
      "Iter 6601 | loss 1.3849\n",
      "Iter 6701 | loss 1.3845\n",
      "Iter 6801 | loss 1.3841\n",
      "Iter 6901 | loss 1.3837\n",
      "Iter 7001 | loss 1.3834\n",
      "Iter 7101 | loss 1.3835\n",
      "Iter 7201 | loss 1.3832\n",
      "Iter 7301 | loss 1.3829\n",
      "Iter 7401 | loss 1.3825\n",
      "Iter 7501 | loss 1.3822\n",
      "Iter 7601 | loss 1.3820\n",
      "Iter 7701 | loss 1.3817\n",
      "Iter 7801 | loss 1.3815\n",
      "Iter 7901 | loss 1.3813\n",
      "Iter 8001 | loss 1.3811\n",
      "Iter 8101 | loss 1.3809\n",
      "Iter 8201 | loss 1.3807\n",
      "Iter 8301 | loss 1.3805\n",
      "Iter 8401 | loss 1.3803\n",
      "Iter 8501 | loss 1.3802\n",
      "Iter 8601 | loss 1.3800\n",
      "Iter 8701 | loss 1.3799\n",
      "Iter 8801 | loss 1.3797\n",
      "Iter 8901 | loss 1.3796\n",
      "Iter 9001 | loss 1.3794\n",
      "Iter 9101 | loss 1.3793\n",
      "Iter 9201 | loss 1.3792\n",
      "Iter 9301 | loss 1.3791\n",
      "Iter 9401 | loss 1.3790\n",
      "Iter 9501 | loss 1.3789\n",
      "Iter 9601 | loss 1.3788\n",
      "Iter 9701 | loss 1.3787\n",
      "Iter 9801 | loss 1.3786\n",
      "Iter 9901 | loss 1.3785\n",
      "Iter 10001 | loss 1.3785\n",
      "Iter 10101 | loss 1.3784\n",
      "Iter 10201 | loss 1.3783\n",
      "Iter 10301 | loss 1.3782\n",
      "Iter 10401 | loss 1.3782\n",
      "Iter 10501 | loss 1.3781\n",
      "Iter 10601 | loss 1.3781\n",
      "Iter 10701 | loss 1.3780\n",
      "Iter 10801 | loss 1.3780\n",
      "Iter 10901 | loss 1.3779\n",
      "Iter 11001 | loss 1.3779\n",
      "Iter 11101 | loss 1.3778\n",
      "Iter 11201 | loss 1.3778\n",
      "Iter 11301 | loss 1.3777\n",
      "Iter 11401 | loss 1.3777\n",
      "Iter 11501 | loss 1.3776\n",
      "Iter 11601 | loss 1.3775\n",
      "Iter 11701 | loss 1.3775\n",
      "Iter 11801 | loss 1.3774\n",
      "Iter 11901 | loss 1.3774\n",
      "Iter 12001 | loss 1.3773\n",
      "Iter 12101 | loss nan\n",
      "Iter 12201 | loss nan\n",
      "Iter 12301 | loss nan\n",
      "Iter 12401 | loss nan\n",
      "Iter 12501 | loss nan\n",
      "Iter 12601 | loss nan\n",
      "Iter 12701 | loss nan\n",
      "Iter 12801 | loss nan\n",
      "Iter 12901 | loss nan\n",
      "Iter 13001 | loss nan\n",
      "Iter 13101 | loss nan\n",
      "Iter 13201 | loss nan\n",
      "Iter 13301 | loss nan\n",
      "Iter 13401 | loss nan\n",
      "Iter 13501 | loss nan\n",
      "Iter 13601 | loss nan\n",
      "Iter 13701 | loss nan\n",
      "Iter 13801 | loss nan\n",
      "Iter 13901 | loss nan\n",
      "Iter 14001 | loss nan\n",
      "Iter 14101 | loss nan\n",
      "Iter 14201 | loss nan\n",
      "Iter 14301 | loss nan\n",
      "Iter 14401 | loss nan\n",
      "Iter 14501 | loss nan\n",
      "Iter 14601 | loss nan\n",
      "Iter 14701 | loss nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-7e3953dbbc2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0midxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mXdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mMLE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-154-f46bf734e220>\u001b[0m in \u001b[0;36mMLE\u001b[0;34m(X, Z, D, Y, estimator, dr)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0moptloss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moptloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-154-f46bf734e220>\u001b[0m in \u001b[0;36mnll\u001b[0;34m(X, Z, D, Y, alpha, beta, eta, gamma, estimator)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MLATE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc5\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1e-10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc5\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc5\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mc5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mp011\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = torch.load('401k.pt')\n",
    "data[:,1] /= 100\n",
    "data[:,4] /= 10\n",
    "data[:,5] \n",
    "data[:,9] /= 10000\n",
    "Z = data[:,0]\n",
    "X = torch.cat((torch.ones((data.shape[0],1)), data[:, [1,2,4,5,9]]), dim=-1)\n",
    "D = data[:,7]\n",
    "Y = data[:,8]\n",
    "\n",
    "N, p = X.shape\n",
    "NR = 1\n",
    "torch.manual_seed(6971)\n",
    "mlealphas = torch.zeros(size=(NR, p))\n",
    "drualphas = torch.zeros(size=(NR, p))\n",
    "minimums, optlosses = [], []\n",
    "for i in range(NR):\n",
    "    idxes = torch.multinomial(torch.ones(N), N, replacement=True)\n",
    "    Xdata = X[idxes].clone()\n",
    "    MLE(X,Z,D,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.min(\n",
      "values=tensor([1.0000, 0.1001, 0.0000, 2.5000, 1.0000, 0.0100]),\n",
      "indices=tensor([   0, 4621,    0,   30,    0, 4621]))\n"
     ]
    }
   ],
   "source": [
    "print(torch.min(X, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
