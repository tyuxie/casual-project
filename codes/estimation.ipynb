{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "def generate(X, alpha, beta, eta, gamma, estimator=\"LATE\"):\n",
    "    phi = torch.sigmoid(X@beta)\n",
    "    c1, c2, c3, c4 = phi[:,0], phi[:,1], phi[:,2], phi[:,3]\n",
    "    if estimator == 'LATE':\n",
    "        c0 = torch.tanh(X @ alpha)\n",
    "    elif estimator == 'MLATE':\n",
    "        c0 = torch.exp(X @ alpha)\n",
    "    c5 = torch.exp(X@eta)\n",
    "    if estimator == 'LATE':\n",
    "        f0 = (c5*(2-c0)+c0-torch.sqrt(c0**2 * (c5-1)**2 + 4*c5)) / (2 * (c5-1))\n",
    "        f1 = f0 + c0\n",
    "    elif estimator == 'MLATE':\n",
    "        f0 = (-(c0+1)*c5+torch.sqrt(c5**2*(c0-1)**2 + 4*c0*c5)) / (2*c0*(1-c5))\n",
    "        f1 = f0 * c0\n",
    "    p011 = (1-c1)*(1-c2)*c3\n",
    "    p001 = (1-c1)*(1-c2)*(1-c3)\n",
    "    p110 = (1-c1)*c2*c4\n",
    "    p100 = (1-c1)*c2*(1-c4)\n",
    "    p111 = f1*c1 + p110\n",
    "    p010 = f0*c1 + p011\n",
    "    p101 = 1-p001-p011-p111\n",
    "    p000 = 1-p010-p100-p110\n",
    "    VIden = torch.sigmoid(X @ gamma)\n",
    "\n",
    "    Z = torch.bernoulli(VIden)\n",
    "\n",
    "    p1 = torch.column_stack((p001, p101, p011, p111))\n",
    "    p0 = torch.column_stack((p000, p100, p010, p110))\n",
    "    p = Z.unsqueeze(1) * p1 + (1-Z).unsqueeze(1) * p0\n",
    "    idx = torch.multinomial(p, num_samples=1).squeeze(1)\n",
    "    cand = torch.LongTensor([[0,0], [1,0], [0,1], [1,1]])\n",
    "    DY = cand[idx]\n",
    "    return Z, DY[:,0], DY[:,1]\n",
    "\n",
    "def nll(X,Z,D,Y,alpha,beta,eta,gamma,estimator='LATE'):\n",
    "    phi = torch.sigmoid(X@beta)\n",
    "    c1, c2, c3, c4 = phi[:,0], phi[:,1], phi[:,2], phi[:,3]\n",
    "    if estimator == 'LATE':\n",
    "        c0 = torch.tanh(X @ alpha)\n",
    "    elif estimator == 'MLATE':\n",
    "        c0 = torch.exp(X @ alpha)\n",
    "    c5 = torch.exp(X@eta)\n",
    "    if estimator == 'LATE':\n",
    "        f0 = (c5*(2-c0)+c0-torch.sqrt(c0**2 * (c5-1)**2 + 4*c5)) / (2 * (c5-1))\n",
    "        f1 = f0 + c0\n",
    "    elif estimator == 'MLATE':\n",
    "        f0 = (-(c0+1)*c5+torch.sqrt(c5**2*(c0-1)**2 + 4*c0*c5)) / (2*c0*(1-c5))\n",
    "        f1 = f0 * c0\n",
    "    p011 = (1-c1)*(1-c2)*c3\n",
    "    p001 = (1-c1)*(1-c2)*(1-c3)\n",
    "    p110 = (1-c1)*c2*c4\n",
    "    p100 = (1-c1)*c2*(1-c4)\n",
    "    p111 = f1*c1 + p110\n",
    "    p010 = f0*c1 + p011\n",
    "    p101 = 1-p001-p011-p111\n",
    "    p000 = 1-p010-p100-p110\n",
    "\n",
    "    d = torch.sigmoid(X@gamma)\n",
    "    l = D*Y*Z*p111*d + (1-D)*Y*Z*p011*d + D*(1-Y)*Z*p101*d + (1-D)*(1-Y)*Z*p001*d + D*Y*(1-Z)*p110*(1-d) + (1-D)*Y*(1-Z)*p010*(1-d) + D*(1-Y)*(1-Z)*p100*(1-d) + (1-D)*(1-Y)*(1-Z)*p000*(1-d)\n",
    "    return torch.mean(torch.log(l.clamp(1e-10)))\n",
    "\n",
    "def square_loss(X, Z, D, Y, alpha, beta, gamma, eta, estimator, strategy='identity'):\n",
    "    d = torch.sigmoid(X@gamma)\n",
    "    phi = torch.sigmoid(X@beta)\n",
    "    phi1, phi2, phi3, phi4 = phi[:,0], phi[:,1], phi[:,2], phi[:,3]\n",
    "    OP = torch.exp(X@eta)\n",
    "    f = (d**Z) * ((1-d)**(1-Z))\n",
    "    if estimator == 'LATE':\n",
    "        theta = torch.tanh(X@alpha)\n",
    "        H = Y - D * theta\n",
    "        f0 = (OP*(2-theta)+theta-torch.sqrt(theta**2*(OP-1)**2+4*OP))/(2*(OP-1))\n",
    "        E = f0*phi1 + (1-phi1)*(1-phi2)*phi3 + (1-phi1)*phi2*phi4 - theta*(1-phi1)*phi2\n",
    "    elif estimator == 'MLATE':\n",
    "        theta = torch.exp(X@alpha)\n",
    "        H = Y * theta**(-D)\n",
    "        f0 = (-(theta+1)*OP+torch.sqrt(OP**2*(theta-1)**2+4*theta*OP)) / (2*theta*(1-OP))\n",
    "        E = f0*phi1 + (1-phi1)*phi2*phi4/theta + (1-phi1)*(1-phi2)*phi3\n",
    "    \n",
    "    if strategy == 'identity':\n",
    "        return torch.sum((torch.sum(X*((2*Z-1)*(H-E)/f).unsqueeze(1), dim=0))**2)\n",
    "\n",
    "def MLE(X, estimator='LATE', dr=True):\n",
    "    alpha0 = torch.tensor([0.0, -1.0])\n",
    "    beta0 = (torch.ones(size=(4,2)) * torch.tensor([-0.4,0.8])).T\n",
    "    eta0 = torch.tensor([-0.4, 1.0])\n",
    "    gamma0 = torch.tensor([0.1, -1.0])\n",
    "    Z, D, Y = generate(X, alpha0, beta0, eta0, gamma0, estimator)\n",
    "    minimum = (-nll(X,Z,D,Y,alpha0,beta0,eta0,gamma0, estimator)).item()\n",
    "    # alpha = nn.Parameter(torch.tensor([0.5, 0.5]))\n",
    "    # beta = nn.Parameter((torch.ones(size=(4,2)) * torch.tensor([-0.5,0.5])).T)\n",
    "    # eta = nn.Parameter(torch.tensor([-0.5, 0.5]))\n",
    "    # gamma = nn.Parameter(torch.tensor([0.2, 0.5]))\n",
    "    alpha = nn.Parameter(torch.rand(size=(2,))*2-1)\n",
    "    beta = nn.Parameter(torch.rand(size=(2,4))*2-1)\n",
    "    eta = nn.Parameter(torch.rand(size=(2,))*2-1)\n",
    "    gamma = nn.Parameter(torch.rand(size=(2,))*2-1)\n",
    "    opt = torch.optim.Adam(params=(alpha, beta, eta, gamma), lr=1e-3, weight_decay=0)\n",
    "    optloss = float('inf')\n",
    "    for i in range(10000):\n",
    "        opt.zero_grad()\n",
    "        loss = -nll(X,Z,D,Y,alpha,beta,eta,gamma, estimator)\n",
    "        if loss.item() < optloss:\n",
    "            if abs(loss.item() - optloss) < 1e-6:\n",
    "                break\n",
    "            optloss = loss.item()\n",
    "            mlealpha = alpha.detach().clone()\n",
    "            mlebeta = beta.detach().clone()\n",
    "            mleeta = eta.detach().clone()\n",
    "            mlegamma = gamma.detach().clone()\n",
    "        # print('Iter {} | loss {:.04f}'.format(i+1, loss.item()))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    if not dr:\n",
    "        return mlealpha, mlebeta, mleeta, mlegamma, minimum, optloss\n",
    "\n",
    "    alpha = nn.Parameter(mlealpha.clone(),requires_grad=True)\n",
    "    # alpha = nn.Parameter(torch.rand(size=(2,))*2-1)\n",
    "    opt = torch.optim.Adam(params=(alpha,), lr=1e-3, weight_decay=0)\n",
    "    sqoptloss = float('inf')\n",
    "    for i in range(10000):\n",
    "        opt.zero_grad()\n",
    "        sq_loss = square_loss(X, Z, D, Y, alpha, mlebeta, mlegamma, mleeta, estimator)\n",
    "        # print('Iter {} | sq_loss {:.04f}'.format(i+1, sq_loss.item()), alpha)\n",
    "        if sq_loss.item() < sqoptloss:\n",
    "            sqoptloss = sq_loss.item()\n",
    "            drualpha = alpha.detach().clone()\n",
    "            if abs(sqoptloss) < 1e-6:\n",
    "                break\n",
    "        sq_loss.backward()\n",
    "        opt.step()\n",
    "    return mlealpha, drualpha, mlebeta, mleeta, mlegamma, minimum, optloss\n",
    "\n",
    "\n",
    "def mle_bth_L():\n",
    "    N = 1000\n",
    "    NR = 1000\n",
    "    torch.manual_seed(24)\n",
    "    mlealphas = torch.zeros(size=(NR, 2))\n",
    "    drualphas = torch.zeros(size=(NR, 2))\n",
    "    minimums, optlosses = [], []\n",
    "    X = torch.column_stack((torch.ones(N)*1.0, torch.rand(N)*2-1))\n",
    "    for i in range(NR):\n",
    "        mlealpha, drualpha, mlebeta, mleeta, mlegamma, minimum, optloss = MLE(X)\n",
    "        print('{} Experiement | Difference {:.04f} | MLEAlpha: ({:.04f}, {:.04f}) | drualpha: ({:.04f}, {:.04f})'.format(i+1, optloss-minimum, mlealpha[0].item(), mlealpha[1].item(), drualpha[0].item(), drualpha[1].item()))\n",
    "        mlealphas[i] = mlealpha\n",
    "        drualphas[i] = drualpha\n",
    "        minimums.append(minimum)\n",
    "        optlosses.append(optloss)\n",
    "    torch.save(mlealphas, 'mle_bth_L')\n",
    "    torch.save(drualphas, 'dru_bth_L')\n",
    "## performs well\n",
    "\n",
    "####### mle.bth \n",
    "def mle_bth_M():\n",
    "    N = 1000\n",
    "    NR = 1000\n",
    "    torch.manual_seed(24)\n",
    "    mlealphas = torch.zeros(size=(NR, 2))\n",
    "    drualphas = torch.zeros(size=(NR, 2))\n",
    "    minimums, optlosses = [], []\n",
    "    X = torch.column_stack((torch.ones(N)*1.0, torch.rand(N)*2-1))\n",
    "    for i in range(NR):\n",
    "        mlealpha, drualpha, mlebeta, mleeta, mlegamma, minimum, optloss = MLE(X, estimator='MLATE')\n",
    "        print('{} Experiement | Difference {:.04f} | MLEAlpha: ({:.04f}, {:.04f}) | drualpha: ({:.04f}, {:.04f})'.format(i+1, optloss-minimum, mlealpha[0].item(), mlealpha[1].item(), drualpha[0].item(), drualpha[1].item()))\n",
    "        mlealphas[i] = mlealpha\n",
    "        drualphas[i] = drualpha\n",
    "        minimums.append(minimum)\n",
    "        optlosses.append(optloss)\n",
    "    torch.save(mlealphas, 'mle_bth_M')\n",
    "    torch.save(drualphas, 'dru_bth_M')\n",
    "\n",
    "## performs well\n",
    "\n",
    "\n",
    "###\n",
    "##对初值敏感(没有先验知识时可能造成无法训练出来)，对学习率敏感\n",
    "##添加贝叶斯先验分布时可能的改进\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Experiement | Difference -0.0022 | MLEAlpha: (0.05266141, -0.83810240)\n",
      "1 Experiement | Difference -0.0022 | drAlpha: (0.19702473, -1.11412072)\n",
      "2 Experiement | Difference -0.0115 | MLEAlpha: (-0.00894787, -0.85652214)\n",
      "2 Experiement | Difference -0.0115 | drAlpha: (-0.08047459, -0.75736469)\n",
      "3 Experiement | Difference -0.0067 | MLEAlpha: (-0.11817837, -0.76484847)\n",
      "3 Experiement | Difference -0.0067 | drAlpha: (0.01471486, -1.19118190)\n",
      "4 Experiement | Difference -0.0056 | MLEAlpha: (0.16162054, -1.28677177)\n",
      "4 Experiement | Difference -0.0056 | drAlpha: (0.25671503, -1.59239709)\n",
      "5 Experiement | Difference -0.0021 | MLEAlpha: (-0.11351624, -1.08117986)\n",
      "5 Experiement | Difference -0.0021 | drAlpha: (-0.12573949, -1.08371985)\n",
      "6 Experiement | Difference -0.0113 | MLEAlpha: (-0.22576459, -0.80976528)\n",
      "6 Experiement | Difference -0.0113 | drAlpha: (-0.27128205, -0.86995608)\n",
      "7 Experiement | Difference -0.0022 | MLEAlpha: (0.03333130, -1.13861251)\n",
      "7 Experiement | Difference -0.0022 | drAlpha: (0.00483290, -1.07129419)\n",
      "8 Experiement | Difference -0.0018 | MLEAlpha: (-0.11213467, -0.64041495)\n",
      "8 Experiement | Difference -0.0018 | drAlpha: (-0.01416073, -0.82754028)\n",
      "9 Experiement | Difference -0.0004 | MLEAlpha: (-0.09300482, -0.82265019)\n",
      "9 Experiement | Difference -0.0004 | drAlpha: (-0.05661592, -1.45000303)\n",
      "10 Experiement | Difference -0.0014 | MLEAlpha: (0.06317391, -0.97433043)\n",
      "10 Experiement | Difference -0.0014 | drAlpha: (0.14665972, -1.14176321)\n",
      "11 Experiement | Difference -0.0067 | MLEAlpha: (0.04308194, -1.10523021)\n",
      "11 Experiement | Difference -0.0067 | drAlpha: (0.03614571, -1.06011951)\n",
      "12 Experiement | Difference -0.0056 | MLEAlpha: (0.06528036, -0.99282920)\n",
      "12 Experiement | Difference -0.0056 | drAlpha: (0.06234438, -0.84653842)\n",
      "13 Experiement | Difference -0.0024 | MLEAlpha: (0.01600872, -0.83318835)\n",
      "13 Experiement | Difference -0.0024 | drAlpha: (-0.00394264, -0.74612743)\n",
      "14 Experiement | Difference -0.0092 | MLEAlpha: (-0.13051401, -0.88643402)\n",
      "14 Experiement | Difference -0.0092 | drAlpha: (-0.17839164, -1.07156956)\n",
      "15 Experiement | Difference -0.0035 | MLEAlpha: (-0.05009392, -0.91290694)\n",
      "15 Experiement | Difference -0.0035 | drAlpha: (-0.02190020, -0.95584923)\n",
      "16 Experiement | Difference -0.0055 | MLEAlpha: (-0.00330878, -0.85804230)\n",
      "16 Experiement | Difference -0.0055 | drAlpha: (0.01074867, -0.97598112)\n",
      "17 Experiement | Difference -0.0067 | MLEAlpha: (0.00506586, -1.22517252)\n",
      "17 Experiement | Difference -0.0067 | drAlpha: (0.06709523, -1.31484294)\n",
      "18 Experiement | Difference -0.0021 | MLEAlpha: (-0.20695312, -1.33428645)\n",
      "18 Experiement | Difference -0.0021 | drAlpha: (-0.09361563, -1.57670832)\n",
      "19 Experiement | Difference -0.0028 | MLEAlpha: (-0.06529855, -0.83826894)\n",
      "19 Experiement | Difference -0.0028 | drAlpha: (-0.02130273, -0.98059630)\n",
      "20 Experiement | Difference -0.0016 | MLEAlpha: (-0.07740486, -0.67634255)\n",
      "20 Experiement | Difference -0.0016 | drAlpha: (-0.05747715, -0.86623371)\n",
      "21 Experiement | Difference 0.0032 | MLEAlpha: (-0.18251312, -0.70586026)\n",
      "21 Experiement | Difference 0.0032 | drAlpha: (-0.17096356, -0.66340709)\n",
      "22 Experiement | Difference 0.0200 | MLEAlpha: (-0.05268719, -0.14372733)\n",
      "22 Experiement | Difference 0.0200 | drAlpha: (0.03503441, -0.95005661)\n",
      "23 Experiement | Difference 0.2972 | MLEAlpha: (0.66289234, -0.46522537)\n",
      "23 Experiement | Difference 0.2972 | drAlpha: (-0.30856392, -1.06312108)\n",
      "24 Experiement | Difference -0.0063 | MLEAlpha: (-0.08232978, -0.97207457)\n",
      "24 Experiement | Difference -0.0063 | drAlpha: (-0.13961485, -1.16136169)\n",
      "25 Experiement | Difference -0.0008 | MLEAlpha: (-0.05671034, -0.82549381)\n",
      "25 Experiement | Difference -0.0008 | drAlpha: (0.04062120, -1.15460300)\n",
      "26 Experiement | Difference -0.0058 | MLEAlpha: (0.03492917, -1.08521378)\n",
      "26 Experiement | Difference -0.0058 | drAlpha: (-0.05463423, -0.68509662)\n",
      "27 Experiement | Difference -0.0039 | MLEAlpha: (-0.04852630, -0.81225175)\n",
      "27 Experiement | Difference -0.0039 | drAlpha: (0.01213893, -0.95271981)\n",
      "28 Experiement | Difference 0.0013 | MLEAlpha: (-0.16795386, -0.60245621)\n",
      "28 Experiement | Difference 0.0013 | drAlpha: (-0.07170378, -1.12370420)\n",
      "29 Experiement | Difference -0.0105 | MLEAlpha: (0.03401566, -1.16579163)\n",
      "29 Experiement | Difference -0.0105 | drAlpha: (0.08876540, -1.23547840)\n",
      "30 Experiement | Difference -0.0083 | MLEAlpha: (0.01508355, -0.99189484)\n",
      "30 Experiement | Difference -0.0083 | drAlpha: (0.13070044, -1.14607286)\n",
      "31 Experiement | Difference -0.0032 | MLEAlpha: (-0.01608511, -0.94470370)\n",
      "31 Experiement | Difference -0.0032 | drAlpha: (0.03975684, -1.02914679)\n",
      "32 Experiement | Difference -0.0037 | MLEAlpha: (-0.16991638, -1.23870552)\n",
      "32 Experiement | Difference -0.0037 | drAlpha: (-0.14636633, -0.98250961)\n",
      "33 Experiement | Difference 0.0007 | MLEAlpha: (-0.07535307, -0.90127575)\n",
      "33 Experiement | Difference 0.0007 | drAlpha: (0.03864609, -1.09919608)\n",
      "34 Experiement | Difference -0.0029 | MLEAlpha: (-0.15049945, -0.49983230)\n",
      "34 Experiement | Difference -0.0029 | drAlpha: (-0.09774889, -0.66988575)\n",
      "35 Experiement | Difference -0.0064 | MLEAlpha: (-0.12885943, -0.87596208)\n",
      "35 Experiement | Difference -0.0064 | drAlpha: (-0.09251107, -0.84674078)\n",
      "36 Experiement | Difference 0.0082 | MLEAlpha: (-0.09737423, -0.44480044)\n",
      "36 Experiement | Difference 0.0082 | drAlpha: (0.07227127, -0.97342348)\n",
      "37 Experiement | Difference -0.0052 | MLEAlpha: (0.12073379, -0.93242973)\n",
      "37 Experiement | Difference -0.0052 | drAlpha: (0.15991715, -1.06024981)\n",
      "38 Experiement | Difference -0.0039 | MLEAlpha: (-0.04781659, -0.65925848)\n",
      "38 Experiement | Difference -0.0039 | drAlpha: (-0.01501016, -0.90918583)\n",
      "39 Experiement | Difference -0.0019 | MLEAlpha: (-0.14656167, -0.39842892)\n",
      "39 Experiement | Difference -0.0019 | drAlpha: (-0.02404303, -0.69762301)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-cdbac7c848f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmle_bth_L\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-cc5eed6fc061>\u001b[0m in \u001b[0;36mmle_bth_L\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mmlealpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdralpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlebeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmleeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlegamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} Experiement | Difference {:.04f} | MLEAlpha: ({:.08f}, {:.08f})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptloss\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlealpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlealpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} Experiement | Difference {:.04f} | drAlpha: ({:.08f}, {:.08f})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptloss\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdralpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdralpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-cc5eed6fc061>\u001b[0m in \u001b[0;36mMLE\u001b[0;34m(X, estimator, dr)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# print('Iter {} | loss {:.04f}'.format(i+1, loss.item()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks_on_exit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_end_callbacks_on_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFuture\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mFuture\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mle_bth_L()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
