{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "def generate(X, alpha, beta, eta, gamma, estimator=\"LATE\"):\n",
    "    phi = torch.sigmoid(X@beta)\n",
    "    c1, c2, c3, c4 = phi[:,0], phi[:,1], phi[:,2], phi[:,3]\n",
    "    if estimator == 'LATE':\n",
    "        c0 = torch.tanh(X @ alpha)\n",
    "    elif estimator == 'MLATE':\n",
    "        c0 = torch.exp(X @ alpha)\n",
    "    c5 = torch.exp(X@eta)\n",
    "    if estimator == 'LATE':\n",
    "        f0 = (c5*(2-c0)+c0-torch.sqrt(c0**2 * (c5-1)**2 + 4*c5)) / (2 * (c5-1))\n",
    "        f1 = f0 + c0\n",
    "    elif estimator == 'MLATE':\n",
    "        f0 = (-(c0+1)*c5+torch.sqrt(c5**2*(c0-1)**2 + 4*c0*c5)) / (2*c0*(1-c5))\n",
    "        f1 = f0 * c0\n",
    "    p011 = (1-c1)*(1-c2)*c3\n",
    "    p001 = (1-c1)*(1-c2)*(1-c3)\n",
    "    p110 = (1-c1)*c2*c4\n",
    "    p100 = (1-c1)*c2*(1-c4)\n",
    "    p111 = f1*c1 + p110\n",
    "    p010 = f0*c1 + p011\n",
    "    p101 = 1-p001-p011-p111\n",
    "    p000 = 1-p010-p100-p110\n",
    "    VIden = torch.sigmoid(X @ gamma)\n",
    "\n",
    "    Z = torch.bernoulli(VIden)\n",
    "\n",
    "    p1 = torch.column_stack((p001, p101, p011, p111))\n",
    "    p0 = torch.column_stack((p000, p100, p010, p110))\n",
    "    p = Z.unsqueeze(1) * p1 + (1-Z).unsqueeze(1) * p0\n",
    "    idx = torch.multinomial(p, num_samples=1).squeeze(1)\n",
    "    cand = torch.LongTensor([[0,0], [1,0], [0,1], [1,1]])\n",
    "    DY = cand[idx]\n",
    "    return Z, DY[:,0], DY[:,1]\n",
    "\n",
    "def nll(X,Z,D,Y,alpha,beta,eta,gamma,estimator='LATE'):\n",
    "    phi = torch.sigmoid(X@beta)\n",
    "    c1, c2, c3, c4 = phi[:,0], phi[:,1], phi[:,2], phi[:,3]\n",
    "    if estimator == 'LATE':\n",
    "        c0 = torch.tanh(X @ alpha)\n",
    "    elif estimator == 'MLATE':\n",
    "        c0 = torch.exp(X @ alpha)\n",
    "    c5 = torch.exp(X@eta)\n",
    "    if estimator == 'LATE':\n",
    "        f0 = (c5*(2-c0)+c0-torch.sqrt(c0**2 * (c5-1)**2 + 4*c5)) / (2 * (c5-1))\n",
    "        f1 = f0 + c0\n",
    "    elif estimator == 'MLATE':\n",
    "        f0 = (-(c0+1)*c5+torch.sqrt(c5**2*(c0-1)**2 + 4*c0*c5)) / (2*c0*(1-c5))\n",
    "        f1 = f0 * c0\n",
    "    p011 = (1-c1)*(1-c2)*c3\n",
    "    p001 = (1-c1)*(1-c2)*(1-c3)\n",
    "    p110 = (1-c1)*c2*c4\n",
    "    p100 = (1-c1)*c2*(1-c4)\n",
    "    p111 = f1*c1 + p110\n",
    "    p010 = f0*c1 + p011\n",
    "    p101 = 1-p001-p011-p111\n",
    "    p000 = 1-p010-p100-p110\n",
    "\n",
    "    d = torch.sigmoid(X@gamma)\n",
    "    l = D*Y*Z*p111*d + (1-D)*Y*Z*p011*d + D*(1-Y)*Z*p101*d + (1-D)*(1-Y)*Z*p001*d + D*Y*(1-Z)*p110*(1-d) + (1-D)*Y*(1-Z)*p010*(1-d) + D*(1-Y)*(1-Z)*p100*(1-d) + (1-D)*(1-Y)*(1-Z)*p000*(1-d)\n",
    "    return torch.mean(torch.log(l.clamp(1e-10)))\n",
    "\n",
    "def square_loss(X, Z, D, Y, alpha, beta, gamma, eta, estimator, strategy='identity'):\n",
    "    d = torch.sigmoid(X@gamma)\n",
    "    phi = torch.sigmoid(X@beta)\n",
    "    phi1, phi2, phi3, phi4 = phi[:,0], phi[:,1], phi[:,2], phi[:,3]\n",
    "    OP = torch.exp(X@eta)\n",
    "    f = (d**Z) * ((1-d)**(1-Z))\n",
    "    if estimator == 'LATE':\n",
    "        theta = torch.tanh(X@alpha)\n",
    "        H = Y - D * theta\n",
    "        f0 = (OP*(2-theta)+theta-torch.sqrt(theta**2*(OP-1)**2+4*OP))/(2*(OP-1))\n",
    "        f1 = f0 + theta\n",
    "        E = f0*phi1 + (1-phi1)*(1-phi2)*phi3 + (1-phi1)*phi2*phi4 - theta*(1-phi1)*phi2\n",
    "    elif estimator == 'MLATE':\n",
    "        theta = torch.exp(X@alpha)\n",
    "        H = Y * theta**(-D)\n",
    "        f0 = (-(theta+1)*OP+torch.sqrt(OP**2*(theta-1)**2+4*theta*OP)) / (2*theta*(1-OP))\n",
    "        f1 = f0 * theta\n",
    "        E = f0*phi1 + (1-phi1)*phi2*phi4/theta + (1-phi1)*(1-phi2)*phi3\n",
    "    \n",
    "    if strategy == 'identity':\n",
    "        return torch.sum((torch.sum(X*((2*Z-1)*(H-E)/f).unsqueeze(1), dim=0))**2)\n",
    "    elif strategy == 'optimal':\n",
    "        p011 = (1-phi1)*(1-phi2)*phi3\n",
    "        p001 = (1-phi1)*(1-phi2)*(1-phi3)\n",
    "        p110 = (1-phi1)*phi2*phi4\n",
    "        p100 = (1-phi1)*phi2*(1-phi4)\n",
    "        p111 = f1*phi1 + p110\n",
    "        p010 = f0*phi1 + p011\n",
    "        p101 = 1-p001-p011-p111\n",
    "        p000 = 1-p010-p100-p110\n",
    "        if estimator == 'LATE':\n",
    "            EH2_1 = p011+p111+ theta**2 * (p111+p101) -2*theta*p111\n",
    "            EH2_0 = p110+p010+theta**2*(p110+p100) -2*theta*p110\n",
    "            EH_1 = p111+p011-theta*(p111+p101)\n",
    "            EH_0 = p110+p010-theta*(p110+p100)\n",
    "            EZX = (EH2_1-EH_1**2) / d + (EH2_0-EH_0**2)/(1-d)\n",
    "            w = -X * ((1/torch.cosh(X@alpha)**2) * phi1 / EZX).unsqueeze(1)\n",
    "            return torch.sum((torch.sum(w*((2*Z-1)*(H-E)/f).unsqueeze(1), dim=0))**2)\n",
    "        elif estimator == 'MLATE':\n",
    "            EH2_1 = p111/theta**2+p101\n",
    "            EH2_0 = p110/theta**2+p100\n",
    "            EH_1 = p111/theta+p101\n",
    "            EH_0 = p110/theta+p100\n",
    "            EZX = (EH2_1-EH_1**2) / d + (EH2_0-EH_0**2)/(1-d)\n",
    "            w = -X * (1 / theta * f1 * phi1 / EZX).unsqueeze(1)\n",
    "            return torch.sum((torch.sum(w*((2*Z-1)*(H-E)/f).unsqueeze(1), dim=0))**2)\n",
    "\n",
    "def MLE(X, estimator='LATE', dr=True):\n",
    "    alpha0 = torch.tensor([0.0, -1.0])\n",
    "    beta0 = (torch.ones(size=(4,2)) * torch.tensor([-0.4,0.8])).T\n",
    "    eta0 = torch.tensor([-0.4, 1.0])\n",
    "    gamma0 = torch.tensor([0.1, -1.0])\n",
    "    Z, D, Y = generate(X, alpha0, beta0, eta0, gamma0, estimator)\n",
    "    minimum = (-nll(X,Z,D,Y,alpha0,beta0,eta0,gamma0, estimator)).item()\n",
    "    # alpha = nn.Parameter(torch.tensor([0.5, 0.5]))\n",
    "    # beta = nn.Parameter((torch.ones(size=(4,2)) * torch.tensor([-0.5,0.5])).T)\n",
    "    # eta = nn.Parameter(torch.tensor([-0.5, 0.5]))\n",
    "    # gamma = nn.Parameter(torch.tensor([0.2, 0.5]))\n",
    "    alpha = nn.Parameter(torch.rand(size=(2,))*2-1)\n",
    "    beta = nn.Parameter(torch.rand(size=(2,4))*2-1)\n",
    "    eta = nn.Parameter(torch.rand(size=(2,))*2-1)\n",
    "    gamma = nn.Parameter(torch.rand(size=(2,))*2-1)\n",
    "    opt = torch.optim.Adam(params=(alpha, beta, eta, gamma), lr=1e-3, weight_decay=0)\n",
    "    optloss = float('inf')\n",
    "    for i in range(10000):\n",
    "        opt.zero_grad()\n",
    "        loss = -nll(X,Z,D,Y,alpha,beta,eta,gamma, estimator)\n",
    "        if loss.item() < optloss:\n",
    "            if abs(loss.item() - optloss) < 1e-6:\n",
    "                break\n",
    "            optloss = loss.item()\n",
    "            mlealpha = alpha.detach().clone()\n",
    "            mlebeta = beta.detach().clone()\n",
    "            mleeta = eta.detach().clone()\n",
    "            mlegamma = gamma.detach().clone()\n",
    "        # print('Iter {} | loss {:.04f}'.format(i+1, loss.item()))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    if not dr:\n",
    "        return mlealpha, mlebeta, mleeta, mlegamma, minimum, optloss\n",
    "\n",
    "    alpha = nn.Parameter(mlealpha.clone(),requires_grad=True)\n",
    "    # alpha = nn.Parameter(torch.rand(size=(2,))*2-1)\n",
    "    opt = torch.optim.Adam(params=(alpha,), lr=1e-3, weight_decay=0)\n",
    "    sqoptloss = float('inf')\n",
    "    for i in range(10000):\n",
    "        opt.zero_grad()\n",
    "        sq_loss = square_loss(X, Z, D, Y, alpha, mlebeta, mlegamma, mleeta, estimator)\n",
    "        # print('Iter {} | sq_loss {:.04f}'.format(i+1, sq_loss.item()), alpha)\n",
    "        if sq_loss.item() < sqoptloss:\n",
    "            sqoptloss = sq_loss.item()\n",
    "            drualpha = alpha.detach().clone()\n",
    "            if abs(sqoptloss) < 1e-6:\n",
    "                break\n",
    "        sq_loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    alpha = nn.Parameter(mlealpha.clone(),requires_grad=True)\n",
    "    opt = torch.optim.Adam(params=(alpha,), lr=1e-3, weight_decay=0)\n",
    "    sqoptloss = float('inf')\n",
    "    for i in range(10000):\n",
    "        opt.zero_grad()\n",
    "        sq_loss = square_loss(X, Z, D, Y, alpha, mlebeta, mlegamma, mleeta, estimator, strategy='optimal')\n",
    "        if sq_loss.item() < sqoptloss:\n",
    "            sqoptloss = sq_loss.item()\n",
    "            drwalpha = alpha.detach().clone()\n",
    "            if abs(sqoptloss) < 1e-6:\n",
    "                break\n",
    "        sq_loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return mlealpha, drualpha, drwalpha, mlebeta, mleeta, mlegamma, minimum, optloss\n",
    "\n",
    "\n",
    "def mle_dr_bth(estimator='LATE'):\n",
    "    N = 1000\n",
    "    NR = 1000\n",
    "    torch.manual_seed(24)\n",
    "    mlealphas = torch.zeros(size=(NR, 2))\n",
    "    drualphas = torch.zeros(size=(NR, 2))\n",
    "    drwalphas = torch.zeros(size=(NR, 2))\n",
    "    minimums, optlosses = [], []\n",
    "    X = torch.column_stack((torch.ones(N)*1.0, torch.rand(N)*2-1))\n",
    "    for i in range(NR):\n",
    "        mlealpha, drualpha,drwalpha, mlebeta, mleeta, mlegamma, minimum, optloss = MLE(X, estimator=estimator, dr=True)\n",
    "        print('{} Experiement | Difference {:.04f} | MLEAlpha: ({:.04f}, {:.04f}) | drualpha: ({:.04f}, {:.04f}) | drwalpha: ({:.04f}, {:.04f})'.format(i+1, optloss-minimum, mlealpha[0].item(), mlealpha[1].item(), drualpha[0].item(), drualpha[1].item(),drwalpha[0].item(), drwalpha[1].item()))\n",
    "        mlealphas[i] = mlealpha\n",
    "        drualphas[i] = drualpha\n",
    "        drwalphas[i] = drwalpha\n",
    "        minimums.append(minimum)\n",
    "        optlosses.append(optloss)\n",
    "    torch.save(mlealphas, 'mle_bth_'+estimator+'.pt')\n",
    "    torch.save(drualphas, 'dru_bth_'+estimator+'.pt')\n",
    "    torch.save(drwalphas, 'drw_bth_'+estimator+'.pt')\n",
    "###\n",
    "##对初值敏感(没有先验知识时可能造成无法训练出来)，对学习率敏感\n",
    "##添加贝叶斯先验分布时可能的改进\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Experiement | Difference -0.0018 | MLEAlpha: (-0.0414, -0.7580) | drualpha: (0.1719, -1.0281) | drwalpha: (0.1272, -0.9389)\n",
      "2 Experiement | Difference -0.0116 | MLEAlpha: (0.0774, -0.8968) | drualpha: (-0.0668, -0.5875) | drwalpha: (-0.0549, -0.5751)\n",
      "3 Experiement | Difference -0.0072 | MLEAlpha: (-0.2442, -0.9318) | drualpha: (0.0452, -1.4075) | drwalpha: (-0.0761, -1.2858)\n",
      "4 Experiement | Difference -0.0066 | MLEAlpha: (0.3685, -1.5548) | drualpha: (0.3331, -1.4654) | drwalpha: (0.2808, -1.4353)\n",
      "5 Experiement | Difference -0.0038 | MLEAlpha: (-0.1538, -1.1427) | drualpha: (-0.1973, -0.9525) | drwalpha: (-0.2187, -0.9894)\n",
      "6 Experiement | Difference -0.0119 | MLEAlpha: (-0.3575, -0.5074) | drualpha: (-0.3348, -0.5356) | drwalpha: (-0.3529, -0.5956)\n",
      "7 Experiement | Difference 0.0023 | MLEAlpha: (-0.0139, -1.1024) | drualpha: (0.1322, -1.2127) | drwalpha: (0.1161, -1.2234)\n",
      "8 Experiement | Difference 0.0002 | MLEAlpha: (-0.3498, -0.6261) | drualpha: (-0.0900, -0.5146) | drwalpha: (-0.1228, -0.5042)\n",
      "9 Experiement | Difference -0.0022 | MLEAlpha: (-0.1731, -0.6571) | drualpha: (-0.2408, -0.9729) | drwalpha: (-0.2441, -0.9330)\n",
      "10 Experiement | Difference 0.0030 | MLEAlpha: (-0.1098, -0.8952) | drualpha: (0.2689, -1.3856) | drwalpha: (0.2504, -1.3968)\n",
      "11 Experiement | Difference -0.0033 | MLEAlpha: (0.0941, -1.2461) | drualpha: (0.3173, -1.8266) | drwalpha: (0.3293, -1.5894)\n",
      "12 Experiement | Difference -0.0041 | MLEAlpha: (0.1462, -1.1313) | drualpha: (0.1169, -0.8573) | drwalpha: (0.2593, -1.1067)\n",
      "13 Experiement | Difference -0.0017 | MLEAlpha: (-0.0718, -0.4907) | drualpha: (-0.0628, -0.4144) | drwalpha: (0.0358, -0.5655)\n",
      "14 Experiement | Difference -0.0074 | MLEAlpha: (-0.2745, -0.8367) | drualpha: (-0.5090, -1.1711) | drwalpha: (-0.4364, -1.0771)\n",
      "15 Experiement | Difference -0.0032 | MLEAlpha: (-0.1053, -0.9984) | drualpha: (-0.0821, -0.9883) | drwalpha: (0.1216, -1.3580)\n",
      "16 Experiement | Difference -0.0056 | MLEAlpha: (-0.1212, -0.8582) | drualpha: (0.0613, -0.9878) | drwalpha: (0.1721, -1.1717)\n",
      "17 Experiement | Difference -0.0079 | MLEAlpha: (0.0073, -1.0634) | drualpha: (0.1102, -1.0336) | drwalpha: (0.1202, -1.1385)\n",
      "18 Experiement | Difference -0.0023 | MLEAlpha: (-0.6174, -0.8941) | drualpha: (-0.3314, -0.9537) | drwalpha: (-0.4232, -0.8132)\n",
      "19 Experiement | Difference -0.0044 | MLEAlpha: (-0.1779, -0.8323) | drualpha: (-0.0871, -0.9089) | drwalpha: (-0.0730, -0.8310)\n",
      "20 Experiement | Difference -0.0003 | MLEAlpha: (-0.2509, -0.4849) | drualpha: (-0.1488, -0.9808) | drwalpha: (-0.1121, -0.8748)\n",
      "21 Experiement | Difference -0.0028 | MLEAlpha: (-0.3134, -0.5582) | drualpha: (-0.2481, -0.7410) | drwalpha: (-0.2201, -0.7347)\n",
      "22 Experiement | Difference -0.0059 | MLEAlpha: (-0.0766, -0.7465) | drualpha: (0.0165, -0.9013) | drwalpha: (-0.0013, -0.9482)\n",
      "23 Experiement | Difference 0.0045 | MLEAlpha: (-0.3045, -1.7630) | drualpha: (0.1408, -2.0483) | drwalpha: (0.1003, -1.7185)\n",
      "24 Experiement | Difference -0.0039 | MLEAlpha: (-0.0181, -0.9970) | drualpha: (-0.0929, -1.2047) | drwalpha: (-0.1812, -1.0746)\n",
      "25 Experiement | Difference 0.0013 | MLEAlpha: (-0.1902, -0.6491) | drualpha: (0.1408, -1.3855) | drwalpha: (0.2247, -1.4724)\n",
      "26 Experiement | Difference -0.0059 | MLEAlpha: (-0.1433, -1.3589) | drualpha: (-0.2002, -0.7253) | drwalpha: (0.0016, -1.0217)\n",
      "27 Experiement | Difference -0.0049 | MLEAlpha: (-0.1221, -0.8411) | drualpha: (0.0251, -0.8997) | drwalpha: (0.0554, -0.8674)\n",
      "28 Experiement | Difference -0.0011 | MLEAlpha: (-0.3331, -0.3363) | drualpha: (-0.1943, -0.8614) | drwalpha: (-0.1055, -0.9564)\n",
      "29 Experiement | Difference -0.0089 | MLEAlpha: (0.0429, -1.5893) | drualpha: (0.2546, -1.3605) | drwalpha: (0.2222, -1.3799)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2acf7ad2f06f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmle_dr_bth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MLATE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-3a5ed6ec70a0>\u001b[0m in \u001b[0;36mmle_dr_bth\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mmlealpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrualpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdrwalpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlebeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmleeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlegamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} Experiement | Difference {:.04f} | MLEAlpha: ({:.04f}, {:.04f}) | drualpha: ({:.04f}, {:.04f}) | drwalpha: ({:.04f}, {:.04f})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptloss\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlealpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlealpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrualpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrualpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdrwalpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrwalpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mmlealphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlealpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-3a5ed6ec70a0>\u001b[0m in \u001b[0;36mMLE\u001b[0;34m(X, estimator, dr)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0moptloss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moptloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-3a5ed6ec70a0>\u001b[0m in \u001b[0;36mnll\u001b[0;34m(X, Z, D, Y, alpha, beta, eta, gamma, estimator)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mp001\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mc3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mp110\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mp100\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mc4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mp111\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mp110\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mp010\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mp011\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mle_dr_bth(estimator='MLATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
