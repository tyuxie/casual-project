{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "def generate(X, alpha, beta, eta, gamma, estimator=\"LATE\"):\n",
    "    phi = torch.sigmoid(X@beta)\n",
    "    c1, c2, c3, c4 = phi[:,0], phi[:,1], phi[:,2], phi[:,3]\n",
    "    if estimator == 'LATE':\n",
    "        c0 = torch.tanh(X @ alpha)\n",
    "    elif estimator == 'MLATE':\n",
    "        c0 = torch.exp(X @ alpha)\n",
    "    c5 = torch.exp(X@eta)\n",
    "    if estimator == 'LATE':\n",
    "        f0 = (c5*(2-c0)+c0-torch.sqrt(c0**2 * (c5-1)**2 + 4*c5)) / (2 * (c5-1))\n",
    "        f1 = f0 + c0\n",
    "    elif estimator == 'MLATE':\n",
    "        f0 = (-(c0+1)*c5+torch.sqrt(c5**2*(c0-1)**2 + 4*c0*c5)) / (2*c0*(1-c5))\n",
    "        f1 = f0 * c0\n",
    "    p011 = (1-c1)*(1-c2)*c3\n",
    "    p001 = (1-c1)*(1-c2)*(1-c3)\n",
    "    p110 = (1-c1)*c2*c4\n",
    "    p100 = (1-c1)*c2*(1-c4)\n",
    "    p111 = f1*c1 + p110\n",
    "    p010 = f0*c1 + p011\n",
    "    p101 = 1-p001-p011-p111\n",
    "    p000 = 1-p010-p100-p110\n",
    "    VIden = torch.sigmoid(X @ gamma)\n",
    "\n",
    "    Z = torch.bernoulli(VIden)\n",
    "\n",
    "    p1 = torch.column_stack((p001, p101, p011, p111))\n",
    "    p0 = torch.column_stack((p000, p100, p010, p110))\n",
    "    p = Z.unsqueeze(1) * p1 + (1-Z).unsqueeze(1) * p0\n",
    "    idx = torch.multinomial(p, num_samples=1).squeeze(1)\n",
    "    cand = torch.LongTensor([[0,0], [1,0], [0,1], [1,1]])\n",
    "    DY = cand[idx]\n",
    "    return Z, DY[:,0], DY[:,1]\n",
    "\n",
    "def nll(X,Xpl, Xpr,Z,D,Y,alpha,beta,eta,gamma,estimator='LATE'):\n",
    "    phi = torch.sigmoid(X@beta)\n",
    "    c1, c2, c3, c4 = phi[:,0], phi[:,1], phi[:,2], phi[:,3]\n",
    "    if estimator == 'LATE':\n",
    "        c0 = torch.tanh(X @ alpha)\n",
    "    elif estimator == 'MLATE':\n",
    "        c0 = torch.exp(X @ alpha)\n",
    "    c5 = torch.exp(X@eta)\n",
    "    if estimator == 'LATE':\n",
    "        f0 = (c5*(2-c0)+c0-torch.sqrt(c0**2 * (c5-1)**2 + 4*c5)) / (2 * (c5-1))\n",
    "        f1 = f0 + c0\n",
    "    elif estimator == 'MLATE':\n",
    "        f0 = (-(c0+1)*c5+torch.sqrt(c5**2*(c0-1)**2 + 4*c0*c5)) / (2*c0*(1-c5))\n",
    "        f1 = f0 * c0\n",
    "    p011 = (1-c1)*(1-c2)*c3\n",
    "    p001 = (1-c1)*(1-c2)*(1-c3)\n",
    "    p110 = (1-c1)*c2*c4\n",
    "    p100 = (1-c1)*c2*(1-c4)\n",
    "    p111 = f1*c1 + p110\n",
    "    p010 = f0*c1 + p011\n",
    "    p101 = 1-p001-p011-p111\n",
    "    p000 = 1-p010-p100-p110\n",
    "\n",
    "    d = torch.sigmoid(Xpl@gamma)\n",
    "    l = D*Y*Z*p111*d + (1-D)*Y*Z*p011*d + D*(1-Y)*Z*p101*d + (1-D)*(1-Y)*Z*p001*d + D*Y*(1-Z)*p110*(1-d) + (1-D)*Y*(1-Z)*p010*(1-d) + D*(1-Y)*(1-Z)*p100*(1-d) + (1-D)*(1-Y)*(1-Z)*p000*(1-d)\n",
    "    return torch.mean(torch.log(l.clamp(1e-10)))\n",
    "\n",
    "def square_loss(X,Xpl,Xpr, Z, D, Y, alpha, beta, gamma, eta, estimator, strategy='identity'):\n",
    "    d = torch.sigmoid(Xpl@gamma)\n",
    "    phi = torch.sigmoid(X@beta)\n",
    "    phi1, phi2, phi3, phi4 = phi[:,0], phi[:,1], phi[:,2], phi[:,3]\n",
    "    OP = torch.exp(X@eta)\n",
    "    f = (d**Z) * ((1-d)**(1-Z))\n",
    "    if estimator == 'LATE':\n",
    "        theta = torch.tanh(X@alpha)\n",
    "        H = Y - D * theta\n",
    "        f0 = (OP*(2-theta)+theta-torch.sqrt(theta**2*(OP-1)**2+4*OP))/(2*(OP-1))\n",
    "        f1 = f0 + theta\n",
    "        E = f0*phi1 + (1-phi1)*(1-phi2)*phi3 + (1-phi1)*phi2*phi4 - theta*(1-phi1)*phi2\n",
    "    elif estimator == 'MLATE':\n",
    "        theta = torch.exp(X@alpha)\n",
    "        H = Y * theta**(-D)\n",
    "        f0 = (-(theta+1)*OP+torch.sqrt(OP**2*(theta-1)**2+4*theta*OP)) / (2*theta*(1-OP))\n",
    "        f1 = f0 * theta\n",
    "        E = f0*phi1 + (1-phi1)*phi2*phi4/theta + (1-phi1)*(1-phi2)*phi3\n",
    "    \n",
    "    if strategy == 'identity':\n",
    "        return torch.sum((torch.sum(X*((2*Z-1)*(H-E)/f).unsqueeze(1), dim=0))**2)\n",
    "    elif strategy == 'optimal':\n",
    "        p011 = (1-phi1)*(1-phi2)*phi3\n",
    "        p001 = (1-phi1)*(1-phi2)*(1-phi3)\n",
    "        p110 = (1-phi1)*phi2*phi4\n",
    "        p100 = (1-phi1)*phi2*(1-phi4)\n",
    "        p111 = f1*phi1 + p110\n",
    "        p010 = f0*phi1 + p011\n",
    "        p101 = 1-p001-p011-p111\n",
    "        if estimator == 'LATE':\n",
    "            EH2_1 = p011+p111+ theta**2 * (p111+p101) -2*theta*p111\n",
    "            EH2_0 = p110+p010+theta**2*(p110+p100) -2*theta*p110\n",
    "            EH_1 = p111+p011-theta*(p111+p101)\n",
    "            EH_0 = p110+p010-theta*(p110+p100)\n",
    "            EZX = (EH2_1-EH_1**2) / d + (EH2_0-EH_0**2)/(1-d)\n",
    "            w = -X * ((1/torch.cosh(X@alpha)**2) * phi1 / EZX).unsqueeze(1)\n",
    "            return torch.sum((torch.sum(w*((2*Z-1)*(H-E)/f).unsqueeze(1), dim=0))**2)\n",
    "        elif estimator == 'MLATE':\n",
    "            EH2_1 = p111/theta**2+p101\n",
    "            EH2_0 = p110/theta**2+p100\n",
    "            EH_1 = p111/theta+p101\n",
    "            EH_0 = p110/theta+p100\n",
    "            EZX = (EH2_1-EH_1**2) / d + (EH2_0-EH_0**2)/(1-d)\n",
    "            w = -X * (1 / theta * f1 * phi1 / EZX).unsqueeze(1)\n",
    "            return torch.sum((torch.sum(w*((2*Z-1)*(H-E)/f).unsqueeze(1), dim=0))**2)\n",
    "\n",
    "def MLE(X, Xpl, Xpr, estimator='LATE', dr=True):\n",
    "    alpha0 = torch.tensor([0.0, -1.0])\n",
    "    beta0 = (torch.ones(size=(4,2)) * torch.tensor([-0.4,0.8])).T\n",
    "    eta0 = torch.tensor([-0.4, 1.0])\n",
    "    gamma0 = torch.tensor([0.1, -1.0])\n",
    "    Z, D, Y = generate(X, alpha0, beta0, eta0, gamma0, estimator)\n",
    "    minimum = (-nll(X,Xpl,Xpr,Z,D,Y,alpha0,beta0,eta0,gamma0, estimator)).item()\n",
    "    # alpha = nn.Parameter(torch.tensor([0.5, 0.5]))\n",
    "    # beta = nn.Parameter((torch.ones(size=(4,2)) * torch.tensor([-0.5,0.5])).T)\n",
    "    # eta = nn.Parameter(torch.tensor([-0.5, 0.5]))\n",
    "    # gamma = nn.Parameter(torch.tensor([0.2, 0.5]))\n",
    "    alpha = nn.Parameter(torch.rand(size=(2,))*2-1)\n",
    "    beta = nn.Parameter(torch.rand(size=(2,4))*2-1)\n",
    "    eta = nn.Parameter(torch.rand(size=(2,))*2-1)\n",
    "    gamma = nn.Parameter(torch.rand(size=(2,))*2-1)\n",
    "    opt = torch.optim.Adam(params=(alpha, beta, eta, gamma), lr=1e-3, weight_decay=0)\n",
    "    optloss = float('inf')\n",
    "    for i in range(10000):\n",
    "        opt.zero_grad()\n",
    "        loss = -nll(X,Xpl,Xpr,Z,D,Y,alpha,beta,eta,gamma, estimator)\n",
    "        if loss.item() < optloss:\n",
    "            if abs(loss.item() - optloss) < 1e-6:\n",
    "                break\n",
    "            optloss = loss.item()\n",
    "            mlealpha = alpha.detach().clone()\n",
    "            mlebeta = beta.detach().clone()\n",
    "            mleeta = eta.detach().clone()\n",
    "            mlegamma = gamma.detach().clone()\n",
    "        # print('Iter {} | loss {:.04f}'.format(i+1, loss.item()))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    if not dr:\n",
    "        return mlealpha, mlebeta, mleeta, mlegamma, minimum, optloss\n",
    "\n",
    "    alpha = nn.Parameter(mlealpha.clone(),requires_grad=True)\n",
    "    # alpha = nn.Parameter(torch.rand(size=(2,))*2-1)\n",
    "    opt = torch.optim.Adam(params=(alpha,), lr=1e-3, weight_decay=0)\n",
    "    sqoptloss = float('inf')\n",
    "    for i in range(10000):\n",
    "        opt.zero_grad()\n",
    "        sq_loss = square_loss(X,Xpl,Xpr, Z, D, Y, alpha, mlebeta, mlegamma, mleeta, estimator)\n",
    "        # print('Iter {} | sq_loss {:.04f}'.format(i+1, sq_loss.item()), alpha)\n",
    "        if sq_loss.item() < sqoptloss:\n",
    "            sqoptloss = sq_loss.item()\n",
    "            drualpha = alpha.detach().clone()\n",
    "            if abs(sqoptloss) < 1e-6:\n",
    "                break\n",
    "        sq_loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    alpha = nn.Parameter(mlealpha.clone(),requires_grad=True)\n",
    "    opt = torch.optim.Adam(params=(alpha,), lr=1e-3, weight_decay=0)\n",
    "    sqoptloss = float('inf')\n",
    "    for i in range(10000):\n",
    "        opt.zero_grad()\n",
    "        sq_loss = square_loss(X,Xpl,Xpr, Z, D, Y, alpha, mlebeta, mlegamma, mleeta, estimator, strategy='optimal')\n",
    "        if sq_loss.item() < sqoptloss:\n",
    "            sqoptloss = sq_loss.item()\n",
    "            drwalpha = alpha.detach().clone()\n",
    "            if abs(sqoptloss) < 1e-6:\n",
    "                break\n",
    "        sq_loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return mlealpha, drualpha, drwalpha, mlebeta, mleeta, mlegamma, minimum, optloss\n",
    "\n",
    "\n",
    "def mle_dr_psc(estimator='LATE'):\n",
    "    N = 1000\n",
    "    NR = 1000\n",
    "    torch.manual_seed(24)\n",
    "    mlealphas = torch.zeros(size=(NR, 2))\n",
    "    drualphas = torch.zeros(size=(NR, 2))\n",
    "    drwalphas = torch.zeros(size=(NR, 2))\n",
    "    minimums, optlosses = [], []\n",
    "    X = torch.column_stack((torch.ones(N)*1.0, torch.rand(N)*2-1))\n",
    "    Xpl = torch.column_stack((torch.ones(N)*1.0, torch.rand(N)*2-1))\n",
    "    Xpr = torch.column_stack((torch.cat((torch.ones(N//2), torch.zeros(N//2))), torch.cat((torch.zeros(N//2), torch.ones(N//2)))))\n",
    "\n",
    "    for i in range(NR):\n",
    "        mlealpha, drualpha,drwalpha, mlebeta, mleeta, mlegamma, minimum, optloss = MLE(X, Xpl, Xpr,  estimator=estimator, dr=True)\n",
    "        print('{} Experiement | Difference {:.04f} | MLEAlpha: ({:.04f}, {:.04f}) | drualpha: ({:.04f}, {:.04f}) | drwalpha: ({:.04f}, {:.04f})'.format(i+1, optloss-minimum, mlealpha[0].item(), mlealpha[1].item(), drualpha[0].item(), drualpha[1].item(),drwalpha[0].item(), drwalpha[1].item()))\n",
    "        mlealphas[i] = mlealpha\n",
    "        drualphas[i] = drualpha\n",
    "        drwalphas[i] = drwalpha\n",
    "        minimums.append(minimum)\n",
    "        optlosses.append(optloss)\n",
    "    torch.save(mlealphas, 'mle_psc_'+estimator+'.pt')\n",
    "    torch.save(drualphas, 'dru_psc_'+estimator+'.pt')\n",
    "    torch.save(drwalphas, 'drw_psc_'+estimator+'.pt')\n",
    "###\n",
    "##对初值敏感(没有先验知识时可能造成无法训练出来)，对学习率敏感\n",
    "##添加贝叶斯先验分布时可能的改进\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Experiement | Difference -0.0361 | MLEAlpha: (0.0562, -0.9884) | drualpha: (0.0505, -0.9917) | drwalpha: (0.0982, -1.1342)\n",
      "2 Experiement | Difference -0.0362 | MLEAlpha: (-0.0185, -1.0933) | drualpha: (-0.0081, -1.1934) | drwalpha: (0.0039, -1.2110)\n",
      "3 Experiement | Difference -0.0421 | MLEAlpha: (-0.1170, -1.4802) | drualpha: (-0.0838, -1.3406) | drwalpha: (0.0131, -1.9106)\n",
      "4 Experiement | Difference -0.0603 | MLEAlpha: (0.1348, -1.0962) | drualpha: (0.1160, -0.9196) | drwalpha: (0.1892, -1.0838)\n",
      "5 Experiement | Difference -0.0655 | MLEAlpha: (0.0720, -0.9210) | drualpha: (0.1341, -1.0356) | drwalpha: (0.1350, -1.0447)\n",
      "6 Experiement | Difference -0.0640 | MLEAlpha: (-0.0206, -0.9166) | drualpha: (-0.0473, -0.8032) | drwalpha: (-0.0326, -0.8174)\n",
      "7 Experiement | Difference -0.0427 | MLEAlpha: (-0.0540, -0.9285) | drualpha: (0.0052, -1.2383) | drwalpha: (0.0095, -1.2908)\n",
      "8 Experiement | Difference -0.0380 | MLEAlpha: (-0.2651, -0.8202) | drualpha: (-0.1682, -0.8926) | drwalpha: (-0.1851, -0.8515)\n",
      "9 Experiement | Difference -0.0519 | MLEAlpha: (-0.1390, -1.0238) | drualpha: (-0.0320, -1.0922) | drwalpha: (-0.0692, -1.0287)\n",
      "10 Experiement | Difference -0.0533 | MLEAlpha: (-0.1804, -0.8558) | drualpha: (-0.1296, -0.8083) | drwalpha: (-0.1264, -0.7809)\n",
      "11 Experiement | Difference -0.0573 | MLEAlpha: (-0.0135, -1.0048) | drualpha: (0.1021, -1.4656) | drwalpha: (0.0663, -1.2566)\n",
      "12 Experiement | Difference -0.0619 | MLEAlpha: (-0.0835, -0.7900) | drualpha: (0.0533, -1.0624) | drwalpha: (0.0142, -0.9618)\n",
      "13 Experiement | Difference -0.0430 | MLEAlpha: (-0.2050, -0.6258) | drualpha: (-0.1284, -0.9424) | drwalpha: (-0.1315, -0.9725)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-352f7091eb49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmle_dr_psc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-77425d935d7c>\u001b[0m in \u001b[0;36mmle_dr_psc\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mmlealpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrualpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdrwalpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlebeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmleeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlegamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXpr\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} Experiement | Difference {:.04f} | MLEAlpha: ({:.04f}, {:.04f}) | drualpha: ({:.04f}, {:.04f}) | drwalpha: ({:.04f}, {:.04f})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptloss\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlealpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlealpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrualpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrualpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdrwalpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrwalpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mmlealphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlealpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-77425d935d7c>\u001b[0m in \u001b[0;36mMLE\u001b[0;34m(X, Xpl, Xpr, estimator, dr)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0msq_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msquare_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXpl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlebeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlegamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmleeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'optimal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msq_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msqoptloss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0msqoptloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msq_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-77425d935d7c>\u001b[0m in \u001b[0;36msquare_loss\u001b[0;34m(X, Xpl, Xpr, Z, D, Y, alpha, beta, gamma, eta, estimator, strategy)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOP\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOP\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOP\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mphi1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mphi1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mphi2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mphi3\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mphi1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mphi2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mphi4\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mphi1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mphi2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MLATE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__rsub__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rdiv__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mle_dr_psc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
